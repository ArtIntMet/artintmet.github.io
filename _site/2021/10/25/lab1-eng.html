<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Examples 1 — Problems | Methods of Computing Intelligence and Decision Making</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Examples 1 — Problems" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We will start the laboratory as simply as possible. We will generate several synthetic datasets and save them later to CSV files." />
<meta property="og:description" content="We will start the laboratory as simply as possible. We will generate several synthetic datasets and save them later to CSV files." />
<link rel="canonical" href="http://localhost:4000/2021/10/25/lab1-eng.html" />
<meta property="og:url" content="http://localhost:4000/2021/10/25/lab1-eng.html" />
<meta property="og:site_name" content="Methods of Computing Intelligence and Decision Making" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-25T00:00:00+02:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Examples 1 — Problems" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2021/10/25/lab1-eng.html"},"url":"http://localhost:4000/2021/10/25/lab1-eng.html","@type":"BlogPosting","headline":"Examples 1 — Problems","dateModified":"2021-10-25T00:00:00+02:00","datePublished":"2021-10-25T00:00:00+02:00","description":"We will start the laboratory as simply as possible. We will generate several synthetic datasets and save them later to CSV files.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Methods of Computing Intelligence and Decision Making" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Methods of Computing Intelligence and Decision Making</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Examples 1 — Problems</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2021-10-25T00:00:00+02:00" itemprop="datePublished">Oct 25, 2021
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>We will start the laboratory as simply as possible. We will generate several synthetic datasets and save them later to CSV files.</p>

<!--more-->

<h2 id="synthetic-data-sets">Synthetic data sets</h2>

<p>As a rule of thumb, in real scientific research (serious research that is supposed to be read by someone) we should rather not use synthetic sets – ie. samples generated by an algorithm that do not present any real problem.</p>

<p>Nevertheless, they turn out to be very useful. They allow us to easily and quickly obtain many different and repeatable (let’s love <code class="language-plaintext highlighter-rouge">random_state</code>) problem variants that meet our requirements. For example, we can generate ten different datasets at once, each of which will have exactly thirty objects (a small number of patterns) with a thousand attributes (high dimensionality of the problem).</p>

<p>A large part of the research work, especially at the beginning of each research, is building prototypes - the first approaches to problems that we should be able to test quickly in order to catch programming and conceptual errors of the method we’ve just invented. Thanks to this, it will be possible to move much faster from the prototyping stage to the construction of a final algorithm, which, of course, will be tested at the end on real datasets.</p>

<h3 id="generating-synthetic-sets">Generating synthetic sets</h3>

<p>Suffice it to convince you that it’s useful and let’s move on to an example.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">make_classification</span><span class="p">()</span>
</code></pre></div></div>

<p>In the first line of the example, from the <a href="https://scikit-learn.org/stable/">scikit-learn library</a> we import the module <a href="https://scikit-learn.org/stable/datasets/index.html">datasets</a> dedicated for loading a few standard datasets (some are 100 years old, so we won’t bother with them for a while) and for generating synthetic datasets. This is done with the function <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"><code class="language-plaintext highlighter-rouge">make_classification()</code></a>, which we called at the end of this short example. It returns a tuple <code class="language-plaintext highlighter-rouge">(X, y)</code>, the first element of which is - according to the definitions we already know - <em>dataset</em>, and the second is <em>a set of labels</em>. Let’s see what size structures are generated by it by default</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; (100, 20) (100,)
</code></pre></div></div>

<p>There are one hundred rows of twenty elements in the data set (matrix <code class="language-plaintext highlighter-rouge">X</code>). This means that we generated a hundred patterns with twenty attributes each. The label set includes (shocking) labels for each of the patterns.</p>

<h3 id="arguments-for-the-make_classification-function">Arguments for the <code class="language-plaintext highlighter-rouge">make_classification()</code> function</h3>

<p>Of course, we can control each of these parameters. For example, let’s generate a dataset containing one thousand eight-dimensional patterns.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; (1000, 8) (1000,)
</code></pre></div></div>

<p>The next parameters (<code class="language-plaintext highlighter-rouge">n_samples</code>,<code class="language-plaintext highlighter-rouge"> n_features</code>) are passed as arguments to the function. The method implemented in it (originally used to generate <a href="http://clopinet.com/isabelle/Projects/NIPS2003/Slides/NIPS2003-Datasets.pdf">Madelon dataset</a> and developed in 1998 by Ms <a href="http://clopinet.com/isabelle/">Isabelle Guyon</a>) accepts many arguments, but we will only list the ones we find most useful for laboratory and project experiments:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_samples</code> — number of generated patterns (default 100).</li>
  <li><code class="language-plaintext highlighter-rouge">n_features</code> — number of problem attributes (default 20).</li>
  <li><code class="language-plaintext highlighter-rouge">n_classes</code> — number of problem classes (default 2, so dichotomy).</li>
  <li><code class="language-plaintext highlighter-rouge">n_clusters_per_class</code> — the number of centroids for each class, and hence the number of clusters of each problem class (default 2).</li>
  <li><code class="language-plaintext highlighter-rouge">flip_y</code> — the noise level, i.e. the number of labels intentionally misassigned (0.01 by default).</li>
  <li><code class="language-plaintext highlighter-rouge">random_state</code> — integer that allows you to generate exactly the same set in each script repetition (default is None, i.e. a random seed of randomness).</li>
</ul>

<p>In addition to these basic properties of the data set, it is worth learning how to control the types of generated attributes for starters. In the case of this generator, all features will be quantitative, but we can modify the characteristics of their usefulness in building the model. The relevant arguments in this case are:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_informative</code> - the number of informative attributes, i.e. those that actually contain information useful for classification, not just noise (2 by default).</li>
  <li><code class="language-plaintext highlighter-rouge">n_redundant</code> - number of redundant attributes that are combinations of informative features (2 by default).</li>
  <li><code class="language-plaintext highlighter-rouge">n_repeated</code> - the number of repeated attributes, i.e. duplicate columns, randomly selected from informative and redundant (2 by default).</li>
</ul>

<p>By default, therefore, a unique (no random seed) binary problem is generated, which consists of one hundred patterns, and only six of its twenty attributes contain potentially useful information (two informative, two are informative combinations and two repeat random from the previous four), and the rest it consists entirely of noise.</p>

<h3 id="lets-invent-a-problem">Let’s invent a problem</h3>

<p>Armed with the knowledge of the parameters of <code class="language-plaintext highlighter-rouge">make_classification()</code>, we can finally invent of a problem. Let it be a reproducible (grain <code class="language-plaintext highlighter-rouge">1410</code>) two-dimensional dataset in which only one attribute is informative (the other has noise) and consists of one hundred patterns with a noise of five percent for the binary problem.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">flip_y</span><span class="o">=</span><span class="p">.</span><span class="mi">05</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1410</span><span class="p">,</span>
    <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div></div>

<p>We generated a two-dimensional set in order to be able to draw its <em>scatterplot</em>. Next, we import the <code class="language-plaintext highlighter-rouge">matplotlib</code> library, prepare a blank 5 by 2.5 inch illustration, draw <em>scatterplot</em> (giving separate columns with dimensions and specifying the color - <code class="language-plaintext highlighter-rouge">c</code> - by the generated labels), describe the axes and save the PNG file.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'bwr'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"$x^1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"$x^2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'scatter.png'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/examples/sroda1.png" alt="" /></p>

<p>As you can see in the attached picture, the first attribute allows to distinguish between classes, so it is informative and the second one contains only noise. Additionally, in both clusters, you can see single objects with an originally incorrect label, making up exactly five objects in total, i.e. five percent of the generated hundred objects.</p>

<h3 id="lets-store-the-problem">Let’s store the problem</h3>

<p>Finally, we will repeat something that I showed you at the beginning of the second lecture. Data sets are often made available as CSV files. In case someone does not know this format, these are <em>very simple</em> text files representing arrays, in which each line describes a single record (in our case, a pattern), and each attribute is separated by a comma.</p>

<blockquote>
  <p>An additional requirement that is often forgotten is to ensure in such a file that each line has exactly the same number of elements (and therefore the same number of separators). A variant of this format is also TSV (tab-separated values), where values are separated by a tab character. If we are stubborn, we can separate the values with any separator we choose, but let’s not charge, for example, to use an asterisk or an exclamation point. No one will understand it, nor will it be of any use to anyone.</p>
</blockquote>

<p>First, we should join the data set and the label set together, adding <code class="language-plaintext highlighter-rouge">y</code> as an additional, last column of the<code class="language-plaintext highlighter-rouge"> X</code> matrix. It is purely arbitrary to consider a set of labels as the last column of a set in serialized form, but we can assume that this is convenient solution.</p>

<p>Here we need <code class="language-plaintext highlighter-rouge">numpy</code> and its built-in function <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"><code class="language-plaintext highlighter-rouge">concatenate()</code></a>. As we can read in the documentation, the first attribute (unnamed and positional) takes “<em>a sequence or an array of arrays of the same shape</em>”. We understand the sequence as the tuple <code class="language-plaintext highlighter-rouge">(X, y)</code>, although we could safely pass an array there as well.</p>

<p>Passing it in the simplest form, however, will result in an error resulting from the fact that we did not provide our numpy arrays with a common shape. We should understand it as:</p>

<ul>
  <li>the same number of dimensions (vector length returned by the array’s <code class="language-plaintext highlighter-rouge">shape</code> attribute),</li>
  <li>the same size in all dimensions except one.</li>
</ul>

<p>Our last generated dataset has dimensions of <code class="language-plaintext highlighter-rouge">(100, 2)</code> and our label set is <code class="language-plaintext highlighter-rouge">(100)</code>, so we do not meet the first of these two conditions. We can make up for this by addressing <code class="language-plaintext highlighter-rouge">y</code> in a way that will generate an extra dimension at its end and start treating it not as a vector, but as a matrix with a single column. We can achieve this by calling <code class="language-plaintext highlighter-rouge">y[:, e.g.newaxis]</code>.</p>

<p>The second essential attribute of the <code class="language-plaintext highlighter-rouge">concatenate()</code> function is <code class="language-plaintext highlighter-rouge">axis</code>, which is the axis on which we plan to join the passed arrays together. We should indicate with it in which dimension (which axis) arrays have different sizes. In our case it is the second parameter, so counting from zero we should pass the value <code class="language-plaintext highlighter-rouge">1</code> there. We can therefore write the correct join as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We can easily save a single matrix in a CSV text file, again using the built-in method <code class="language-plaintext highlighter-rouge">numpy</code> [<code class="language-plaintext highlighter-rouge">savetxt()</code>] (https://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html).</p>

<p>It has two positional arguments. In the first, we give a string with the filename, in the second, the array we want to save. Additionally, if we want to meet CSV format requirements, we should also change the default separator to comma.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s">"dataset.csv"</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
</code></pre></div></div>

<p>This is supposed to be enough, but if we look at the contents of the file, we will see that it does not look very beautiful.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-1.060890925868820389e+00,2.455805509796364028e+00,0.000000000000000000e+00
-6.853148372231210317e-01,-1.500489680108889390e+00,0.000000000000000000e+00
7.775378070067257008e-01,1.330505069088626868e+00,1.000000000000000000e+00
6.933842893245101280e-01,7.217146432694194758e-01,1.000000000000000000e+00
-2.715820952605125793e-01,7.934501868603156538e-01,1.000000000000000000e+00
</code></pre></div></div>

<p>If one is a lover of scientific notation, of course, he can leave it as it is, but it must be honestly admitted that writing a label, which is ultimately an integer from a cavernous, discrete set of only zero and one, as a number in mathematical notation with precision of eighteen a decimal place is somewhat backbreaking. We can fix it by specifying the number format manually. I won’t explain it in detail right now, but believe it, it works.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">savetxt</span><span class="p">(</span>
    <span class="s">"dataset.csv"</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">,</span>
    <span class="n">fmt</span><span class="o">=</span><span class="p">[</span><span class="s">"%.5f"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="s">"%i"</span><span class="p">],</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-1.06089,2.45581,0
-0.68531,-1.50049,0
0.77754,1.33051,1
0.69338,0.72171,1
-0.27158,0.79345,1
</code></pre></div></div>

<p>Better right now, right?</p>

<h3 id="lets-go-back-to-the-old-problem">Let’s go back to the old problem</h3>

<p>Okay, finally let’s see how to read CSV files into <code class="language-plaintext highlighter-rouge">numpy</code> arrays. Again, we have a built-in function for this, called <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html"><code class="language-plaintext highlighter-rouge">genfromtxt ()</code></a>. So let’s read the file into the variable <code class="language-plaintext highlighter-rouge">dataset</code> (remembering about the separator) and see how it loaded beautifully.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">"dataset.csv"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; [[-1.06089  2.45581  0.     ]
&gt;&gt;  [-0.68531 -1.50049  0.     ]
&gt;&gt;  [ 0.77754  1.33051  1.     ]
&gt;&gt;  [ 0.69338  0.72171  1.     ]
&gt;&gt;  [-0.27158  0.79345  1.     ]
...
</code></pre></div></div>

<p>Since it’s already loaded, let’s divide it into <code class="language-plaintext highlighter-rouge">X</code> and<code class="language-plaintext highlighter-rouge"> y</code>, assigning all columns except the last one to the first one, and only the last one to the second one. Since the labels are integers anyway, let’s cast it to an integer by the way.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div>

<p>Beautiful. We can already carry out such advanced tasks as coming up with a problem and saving it for later, so that we can always come back to it. Perfectly.</p>

  </div><a class="u-url" href="/2021/10/25/lab1-eng.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Methods of Computing Intelligence and Decision Making</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Methods of Computing Intelligence and Decision Making</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
